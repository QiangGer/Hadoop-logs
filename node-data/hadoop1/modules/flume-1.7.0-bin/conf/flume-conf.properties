agent1.sources = s1
agent1.channels = kafkaC hbaseC 
agent1.sinks = kafkaSink hbaseSink


# 从hadoop-2和3上拿的数据，然后传给两个channels
agent1.sources.s1.type = avro
agent1.sources.s1.bind = hadoop-1
agent1.sources.s1.port = 5555
agent1.sources.s1.threads = 5
agent1.sources.s1.channels = hbaseC kafkaC


#*************** flume + hbase ***********************

agent1.channels.hbaseC.type = memory
agent1.channels.hbaseC.capacity = 10000
agent1.channels.hbaseC.transactionCapacity = 10000
agent1.channels.hbaseC.keep-alive = 20

agent1.sinks.hbaseSink.channel = hbaseC
agent1.sinks.hbaseSink.type = asynchbase
agent1.sinks.hbaseSink.table = weblogs
agent1.sinks.hbaseSink.columnFamily = info
agent1.sinks.hbaseSink.serializer = org.apache.flume.sink.hbase.KfkAsyncHbaseEventSerializer
agent1.sinks.hbaseSink.serializer.payloadColumn = datetime,userid,searchname,retorder,cliorder,cliurl


#****************************flume + kafka******************************

agent1.channels.kafkaC.type = memory
agent1.channels.kafkaC.capacity = 10000
agent1.channels.kafkaC.transactionCapacity = 10000
agent1.channels.kafkaC.keep-alive = 20

agent1.sinks.kafkaSink.channel = kafkaC
agent1.sinks.kafkaSink.type = org.apache.flume.sink.kafka.KafkaSink
agent1.sinks.kafkaSink.brokerList = hadoop-1:9092,hadoop-2:9092,hadoop-3:9092
agent1.sinks.kafkaSink.topic = weblogs
agent1.sinks.kafkaSink.zookeeperConnect = hadoop-1:2181,hadoop-2:2181,hadoop-3:2181
agent1.sinks.kafkaSink.requiredAcks = 1
agent1.sinks.kafkaSink.batchSize = 1
agent1.sinks.kafkaSink.serializer.class = kafka.serializer.StringEncoder
